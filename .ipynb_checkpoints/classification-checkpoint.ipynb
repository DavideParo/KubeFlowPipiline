{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (1.4.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (1.19.5)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (0.23.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 1)) (2022.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.6.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 1)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "block:dowload_data"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def download_data(out_file):\n",
    "\n",
    "    # Gets and split dataset\n",
    "    x, y = load_breast_cancer(return_X_y=True)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "    # Creates `data` structure to save and \n",
    "    # share train and test datasets.\n",
    "    data = {'x_train' : x_train.tolist(),\n",
    "            'y_train' : y_train.tolist(),\n",
    "            'x_test' : x_test.tolist(),\n",
    "            'y_test' : y_test.tolist()}\n",
    "\n",
    "    # Creates a json object based on `data`\n",
    "    data_json = json.dumps(data)\n",
    "\n",
    "\n",
    "    # Saves the json object into a file\n",
    "    with open(out_file, 'w') as f:\n",
    "        json.dump(data_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "block:decision_tree",
     "prev:dowload_data"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from joblib import dump\n",
    "\n",
    "def decision_tree(data_file):\n",
    "\n",
    "    # Open and reads file \"data\"\n",
    "    with open(data_file) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # The excted data type is 'dict', however since the file\n",
    "    # was loaded as a json object, it is first loaded as a string\n",
    "    # thus we need to load again from such string in order to get \n",
    "    # the dict-type object.\n",
    "    data = json.loads(data)\n",
    "\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['y_test']\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    model = DecisionTreeClassifier(max_depth=3)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # Save the model\n",
    "    dump(model, 'models/decision_tree_model.joblib')\n",
    "\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    # Get accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "block:random_forest",
     "prev:dowload_data"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import dump\n",
    "\n",
    "def random_forest(data_file):\n",
    "\n",
    "    # Open and reads file \"data\"\n",
    "    with open(data_file) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # The excted data type is 'dict', however since the file\n",
    "    # was loaded as a json object, it is first loaded as a string\n",
    "    # thus we need to load again from such string in order to get \n",
    "    # the dict-type object.\n",
    "    data = json.loads(data)\n",
    "\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['y_test']\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    model = RandomForestClassifier(n_estimators=100, bootstrap = True, max_features = 'sqrt')\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # Save the model\n",
    "    dump(model, 'models/random_forest_model.joblib')\n",
    "\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    # Get accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": [
     "block:show_results",
     "prev:decision_tree",
     "prev:random_forest"
    ]
   },
   "outputs": [],
   "source": [
    "def show_results(accuracy_file, accuracy_dt, accuracy_rf):\n",
    "    # Given the outputs from decision_tree and logistic regression components\n",
    "    # the results are shown.\n",
    "    # Save output into file\n",
    "    with open(accuracy_file, 'w') as f:\n",
    "        f.write('Decision tree (accuracy): ' + str(accuracy_dt))\n",
    "        f.write('Random forest (accuracy): ' + str(accuracy_rf))\n",
    "\n",
    "    print(f\"Decision tree (accuracy): {accuracy_dt}\")\n",
    "    print(f\"Random forest (accuracy): {accuracy_rf}\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "block:classify",
     "prev:dowload_data",
     "prev:decision_tree",
     "prev:show_results"
    ]
   },
   "outputs": [],
   "source": [
    "def classify():\n",
    "    data_file = 'data/dataset.csv'\n",
    "    accuracy_file = 'results/accuracy.txt'\n",
    "    # Run download_data task\n",
    "    download_data(data_file)\n",
    "\n",
    "    # Run tasks \"decison_tree\" and \"logistic_regression\" given\n",
    "    # the output generated by \"download\".\n",
    "    accuracy_dt = decision_tree(data_file)\n",
    "    accuracy_rf = random_forest(data_file)\n",
    "\n",
    "    # Given the outputs from \"decision_tree\" and \"logistic_regression\"\n",
    "    # the component \"show_results\" is called to print the results.\n",
    "    show_results(accuracy_file, accuracy_dt, accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree (accuracy): 0.9385964912280702\n",
      "Random forest (accuracy): 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": true,
   "deploy_config": {},
   "docker_image": "gcr.io/arrikto/jupyter-kale-py38@sha256:2e1ce3427b780c0c78e7cfec527ee10c391092fdc4a8344cd76f8b83c61c5234",
   "experiment_name": "classification",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "classification-dtrf",
   "snapshot_volumes": true,
   "volume_access_mode": "rwm",
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/home/jovyan",
     "name": "classification-workspace-fhx68",
     "size": 1,
     "size_type": "Gi",
     "snapshot": false,
     "type": "clone"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
